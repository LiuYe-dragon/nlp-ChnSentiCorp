{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2675c029-cd3f-49d0-8519-0fa8ef1ba7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4aa5732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 100\n",
    "EMBEDDING_DIM = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 6\n",
    "split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b021326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(tabel='train'):\n",
    "    file = './datasets/'+tabel+'.tsv'\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    df = df.dropna()\n",
    "    texts = df['text_a'].astype(str).tolist()\n",
    "    if tabel == 'test':\n",
    "        labels = None\n",
    "    else:\n",
    "        labels = df['label'].astype(int).tolist()\n",
    "        \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "539d63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = load_dataset()\n",
    "test_texts, test_labels = load_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a52e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(filep='./datasets/stopwords.txt'):\n",
    "    with open(filep,encoding='utf-8') as f:\n",
    "        return set([w.strip() for w in f.readlines()])\n",
    "stopwords = load_stopwords()\n",
    "def chinese_tokenizer(text):\n",
    "    return [w for w in jieba.lcut(text) if w not in stopwords and w.strip()]\n",
    "def text_cut(texts):\n",
    "    return [' '.join(chinese_tokenizer(text)) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e681783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut = text_cut(train_texts)\n",
    "test_cut = text_cut(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1763f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(train_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baf14ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_cut)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04530264",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(train_sequences,maxlen=MAX_SEQ_LEN)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "x_test = pad_sequences(test_sequences, maxlen=MAX_SEQ_LEN)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd1721e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "db_train = db_train.shuffle(1000).batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n",
    "db_val = db_train.skip(int(len(db_train)*(1-split)))\n",
    "db_train = db_train.take(int(len(db_train)*(1-split)))\n",
    "\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db_test = db_test.shuffle(1000).batch(BATCH_SIZE,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "977961c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_VOCAB_SIZE,EMBEDDING_DIM,input_length=MAX_SEQ_LEN))\n",
    "model.add(LSTM(128,dropout=0.3))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2778b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,695,745\n",
      "Trainable params: 2,695,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef732647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45852658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "99/99 [==============================] - 8s 56ms/step - loss: 0.6388 - accuracy: 0.6314 - val_loss: 0.4086 - val_accuracy: 0.8198\n",
      "Epoch 2/6\n",
      "99/99 [==============================] - 5s 50ms/step - loss: 0.2740 - accuracy: 0.8932 - val_loss: 0.2797 - val_accuracy: 0.8870\n",
      "Epoch 3/6\n",
      "99/99 [==============================] - 5s 51ms/step - loss: 0.1121 - accuracy: 0.9616 - val_loss: 0.2898 - val_accuracy: 0.8859\n",
      "Epoch 4/6\n",
      "99/99 [==============================] - 5s 52ms/step - loss: 0.0578 - accuracy: 0.9828 - val_loss: 0.3004 - val_accuracy: 0.8928\n",
      "Epoch 5/6\n",
      "99/99 [==============================] - 5s 53ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.3313 - val_accuracy: 0.8935\n",
      "Epoch 6/6\n",
      "99/99 [==============================] - 5s 52ms/step - loss: 0.0382 - accuracy: 0.9893 - val_loss: 0.3910 - val_accuracy: 0.8986\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(db_train,epochs=EPOCHS, validation_data=db_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbd00d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5456 - accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5456445813179016, 0.8654513955116272]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98c884b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('./models',exist_ok=True)\n",
    "model.save('./models/lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
